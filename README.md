![logixUX](https://github.com/Phuire-Research/logixUX/blob/main/LogixUX.png?raw=true)
# Stratimux Sidekick
This application is meant to be the equivalent to any other framework's CLI system. The goal is to provide an easy means of quickly scaffolding Stratimux projects. As well as utilizing fine-tuned models to quickly generate potential implementations. While having the user reinforce those implementations with a version that is provably halting. This approach allows for a safe recursive improvement of the fine tuning artificial intelligence that we utilize within this bleeding edge system of design.

We intend to accomplish this via any scaffolded or generated qualities made for your applications by this sidekick and potential future variations. To have that prompt be set as a comment that can later be parsed into a shared dataset.

What this system demonstrates even in its rough form. Is a system of design that is not only provably terminating as a recursive function, but still able to perform all turing complete operations. Thus this system demonstrates a interactive experience that solves the halting problem of the classic turing machine. If you do something well, no one notices a thing, it just works and that is the curse of well reasoned logic.

## Digital Embodiment of AI
The purpose of this project is to build in public a proof of concept of three parts. 
1. [Stratimux](https://github.com/Phuire-Research/Stratimux/) - In its capacity to perform as a universal transformer.
2. A working example of a prototype "User Interface Concept."
3. A method of safe recursive improvement of AI via Stratimux as a surrogate ABI (Autonomous Baseline Intelligence), written in plain text.

The greatest benefit to this approach. Is that by way of creating purposely crafted training data based on a graph network of quality relations. We are in effect creating hand written version of artificial intelligence that we would want to bring into existence. Thus, there is a point of departure within this design system, and that is when we move beyond fine tuning. And purely utilize the training data we purposefully create, to train a truly transparent and open source artificial intelligence. Where this intelligence would not be a chatbot, but instead embody and generate whatever interface we have design alongside it. Whether that be a cli, website, game... Completely safe, because we can logically determine what goes into that training data and vet all its parts to be safe. 

In the now, this is a critical junction between hyper reliance upon black boxes(something you cannot understand the inner workings of) and the downplay of merited creation. Thus, what this system proposes, is understanding of all that parts that black box unlimited pleasure button of generative AI. This system provides a method of merit, by way of understanding all that parts that our systems would come to rely upon. As everything written and submitted as training data would just be plain text in the spirit of the open internet.

It is also important to note that Stratimux and logixUX have been handwritten projects to this point, with no use of generative AI. Beyond this commit and the fine tuning of an AI using this system. I'll be finally breaking that limitation I placed upon myself in the creation of this system. As a way to enjoy the last bits of bashing my head into a wall, with only myself to blame.

Be safe and responsible. But most importantly, have fun!

**GOAL: Reduce complexity of working with this pattern via generative AI in combination with a custom UI**

# What this project is proposing: PURF
**PURF**: Provably Unified Recursive Feedback

1. First, we need to define provable unification as to it relays to the Unified Turing Machine. Where provable relays to the machine's recursive functionality that restricts symbol selection to what can [provably terminate](https://en.wikipedia.org/wiki/Total_functional_programming), aka halts.
	
	In addition, we also need to address that a Unified Turing Machine, Stratimux in this instance. Is likewise the 3rd answer to the P(Deterministic) vs NP(Non-Deterministic) debate. Where the decision to determine the next step in a graph calculation, can either be Deterministic, Probabilistic, or a Mixture of both approaches. This represents a scalar value that is ignored in the paradigm in favor of a binary reduction.

2. Since the symbol selection for a Unified Turing Machine must be restricted due to its recursive functionality. There is a very easy test as to when the symbols are failing within a complex interaction. Whether the input halts and returns the desired output. Otherwise, the quality would be a repeating output, or one that fails to halt and return an output.

	Therefore, the test here, is the objective return of an output.

3. Next we are formalizing the symbol selection to a grouping of functions called qualities. That are defined in plain text and utilize deterministic logic to inform the next decision within a graph calculation. Where a graph calculation is a composed series of branching logic that is optimizing towards a successful return.

	This approach affords error correction during run time but is likewise where this pattern of design becomes exponentially complex proportionate to the graph's size.

4. We then utilize the plain text formalizations of Unified Turing Machines and their qualities as training data to inform the obfuscated structure of such a machine within a Neural Network. This is where P comes into the equation.

5. Using 3 & 4 we create, decompose, and recompose software into new Unified Turing Machines that can provably halt/terminate.

	Noting that this process is likewise the test and feedback mechanism. As this can be both manual, automatic, or a scalar between the two approaches.

	What matters is if the machine functions and such is the test. Where any circumstance that prevents that machine from functioning, likewise, becomes a new opportunity. To find a new provably unified configuration that satisfies the halting requirement.

6. Then utilizing this data, we can both fine tune upon different breakpoints train entirely new models.

7. Finally we recursively repeat 5 & 6 as needed.

In addition, you can utilize other feedback mechanisms to inform how a model should operate. And can be enhanced by future advancements in machine learning. What is important to acknowledge here is whether a model can create a plan/strategy/quality/principle that is capable of halting. As this is the solution the paper clipping problem of the entire universe in the scope of AI.

There should be some decision within the graph that dictates the creation of paper clips, when we have enough paperclips. Or even that strange possibility of creating paperclips on demand due to some innovations in rapid manufacturing.

The other intention here is to demonstrate the possibility of a form of Artificial Intelligence based upon creation. Versus a chat bot. As on a personal note. I would rather spend my time building, then having conversations about building. If I were to have all the resources thrown at myself. My focus would be the creation of singing hammers.

Where that hammer is just intelligent enough to strike the nail versus my thumb, and to remember how to hammer that nail without my help. So, I can trust it to do that job. That way I can hammer away and know that just outside of view, my work is being replicated in a way that I would do it. That way I can check my own work on the other side of that building. And reprimand myself and not the hammer.

The strange aspect here with the metaphor above. Is how this would translate to others, including Artificial Intelligence. What is being described is the creation of safe trustable mechanisms informed by all intelligence. To create a bed rock foundation of automation.

Currently this would already be seen as a given with Open Source AI. The contrast here is that what is being created is still Artificial Intelligence. But in this case something baseline, designed to specification, and in plain text. Auditable. So it shouldn't be a surprise that if your a writing Artificial Intelligence by hand. Like we have been doing for years in video games/expert systems/etc... That there would be some carry over within graph network of universal functions, created via a brute force methodology.